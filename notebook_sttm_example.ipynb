{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T16:48:17.389579Z",
     "start_time": "2019-08-22T16:48:15.021522Z"
    }
   },
   "outputs": [],
   "source": [
    "from preprocessing import tokenize, export_to_csv\n",
    "from gsdmm import MovieGroupProcess\n",
    "from topic_allocation import top_words, topic_attribution\n",
    "from visualisation import plot_topic_notebook, save_topic_html\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "\n",
    "import pickle\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling on 20NewsGroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T16:48:21.581187Z",
     "start_time": "2019-08-22T16:48:20.019532Z"
    }
   },
   "outputs": [],
   "source": [
    "cats = ['talk.politics.mideast', 'comp.windows.x', 'sci.space']\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), categories=cats)\n",
    "newsgroups_train_subject = fetch_20newsgroups(subset='train', categories=cats)\n",
    "\n",
    "data = newsgroups_train.data\n",
    "data_subject = newsgroups_train_subject.data\n",
    "\n",
    "targets = newsgroups_train.target.tolist()\n",
    "target_names = newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T16:48:23.125998Z",
     "start_time": "2019-08-22T16:48:23.110889Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    593\n",
       "0    593\n",
       "2    564\n",
       "Name: targets, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see if our topics are evenly distributed\n",
    "df_targets = pd.DataFrame({'targets': targets})\n",
    "order_list = df_targets.targets.value_counts()\n",
    "order_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T16:48:29.738066Z",
     "start_time": "2019-08-22T16:48:29.704974Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Elevator to the top floor Reading from a Amoco Performance Products data sheet, theirERL-1906 resin with T40 carbon fiber reinforcement has a compressivestrength of 280,000 psi', 'Title for XTerm Yet again,the escape sequences you are speaking about here are non standard anddangerous', 'From Israeli press. Madness. Before getting excited and implying that I am postingfabrications, I would suggest the readers to consult thenewspaper in question', 'Accounts of Anti-Armenian Human Right Violations in Azerbaijan #011 Accounts of Anti-Armenian Human Right Violations in Azerbaijan #011                 Prelude to Current Events in Nagorno-Karabakh        +-------------------------------------------------------+        |                                                       |        |   \"Right, we should slaughter the Armenians!\" and     |        |    \"There\\'s no need to be afraid, all of Moscow is    |        |    behind us', \"How many israeli soldiers does it take to kill a 5 yr old child? Probably not--he's just singing someone else's opera\"]\n"
     ]
    }
   ],
   "source": [
    "def extract_first_sentence(data_subject):\n",
    "    list_first_sentence = []\n",
    "    for text in data:\n",
    "        first_sentence = text.split(\".\")[0].replace(\"\\n\", \"\")\n",
    "        list_first_sentence.append(first_sentence)\n",
    "    return list_first_sentence\n",
    "\n",
    "\n",
    "def extract_subject(data):\n",
    "    c = 0\n",
    "    s = \"Subject:\"\n",
    "    list_subjects = []\n",
    "    for new in data_subject:    \n",
    "        lines = new.split(\"\\n\")\n",
    "        b = 0 # loop out at the first \"Subject:\", they may be several and we want first one only\n",
    "        for line in lines:\n",
    "            if s in line and b == 0:\n",
    "                subject = \" \".join(line.split(\":\")[1:]).strip()\n",
    "                subject = subject.replace('Re', '').strip()\n",
    "                list_subjects.append(subject)\n",
    "                c += 1\n",
    "                b = 1\n",
    "    return list_subjects\n",
    "   \n",
    "    \n",
    "def concatenate(list_first_sentence, list_subjects):\n",
    "    list_docs = []\n",
    "    for i in range(len(list_first_sentence)):\n",
    "        list_docs.append(list_subjects[i] + \" \" + list_first_sentence[i])\n",
    "    return list_docs\n",
    "\n",
    "\n",
    "list_first_sentence = extract_first_sentence(data)\n",
    "list_subjects = extract_subject(data_subject)\n",
    "list_docs = concatenate(list_first_sentence, list_subjects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T16:48:32.623638Z",
     "start_time": "2019-08-22T16:48:32.598981Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>topic_id</th>\n",
       "      <th>topic_true_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elevator to the top floor Reading from a Amoco...</td>\n",
       "      <td>1</td>\n",
       "      <td>space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Title for XTerm Yet again,the escape sequences...</td>\n",
       "      <td>0</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From Israeli press. Madness. Before getting ex...</td>\n",
       "      <td>2</td>\n",
       "      <td>mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Accounts of Anti-Armenian Human Right Violatio...</td>\n",
       "      <td>2</td>\n",
       "      <td>mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How many israeli soldiers does it take to kill...</td>\n",
       "      <td>2</td>\n",
       "      <td>mideast</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  topic_id topic_true_name\n",
       "0  Elevator to the top floor Reading from a Amoco...         1           space\n",
       "1  Title for XTerm Yet again,the escape sequences...         0               x\n",
       "2  From Israeli press. Madness. Before getting ex...         2         mideast\n",
       "3  Accounts of Anti-Armenian Human Right Violatio...         2         mideast\n",
       "4  How many israeli soldiers does it take to kill...         2         mideast"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['content', 'topic_id', 'topic_true_name'])\n",
    "df['content'] = list_docs\n",
    "df['topic_id'] = targets\n",
    "\n",
    "def true_topic_name(x, target_names):\n",
    "    return target_names[x].split('.')[-1]\n",
    "\n",
    "df['topic_true_name'] = df['topic_id'].apply(lambda x: true_topic_name(x, target_names))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization & preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T16:48:54.084891Z",
     "start_time": "2019-08-22T16:48:35.264273Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-22 18:48:35,265 :: [INFO] :: ---- Tokenization started ----\n",
      "2019-08-22 18:48:35,266 :: [INFO] :: Initializing the preprocessing...\n",
      "2019-08-22 18:48:35,737 :: [INFO] :: Spacy tokenization...\n",
      "2019-08-22 18:48:52,273 :: [INFO] :: Stop words and one character words removing...\n",
      "2019-08-22 18:48:52,289 :: [INFO] :: Stemming...\n",
      "2019-08-22 18:48:52,788 :: [INFO] :: Remove numeric and empty...\n",
      "2019-08-22 18:48:52,878 :: [INFO] :: Removing unique tokens...\n",
      "2019-08-22 18:48:54,072 :: [INFO] :: ---- Tokenization completed ----\n"
     ]
    }
   ],
   "source": [
    "tokenized_data = tokenize(df, form_reduction='stemming', predict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T16:48:56.198135Z",
     "start_time": "2019-08-22T16:48:56.180528Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>tokens</th>\n",
       "      <th>topic_true_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elevator to the top floor Reading from a Amoco...</td>\n",
       "      <td>[read, perform, product, data, t, carbon, fibe...</td>\n",
       "      <td>space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Title for XTerm Yet again,the escape sequences...</td>\n",
       "      <td>[titl, xterm, escap, sequenc, speak, non, stan...</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From Israeli press. Madness. Before getting ex...</td>\n",
       "      <td>[isra, press, mad, get, excit, impli, suggest,...</td>\n",
       "      <td>mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How many israeli soldiers does it take to kill...</td>\n",
       "      <td>[isra, soldier, kill, yr, old, child, probabl]</td>\n",
       "      <td>mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NEWS YOU MAY HAVE MISSED, Apr 20 NEWS YOU MAY ...</td>\n",
       "      <td>[news, miss, apr, news, miss, apr,           ,...</td>\n",
       "      <td>mideast</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0  Elevator to the top floor Reading from a Amoco...   \n",
       "1  Title for XTerm Yet again,the escape sequences...   \n",
       "2  From Israeli press. Madness. Before getting ex...   \n",
       "4  How many israeli soldiers does it take to kill...   \n",
       "5  NEWS YOU MAY HAVE MISSED, Apr 20 NEWS YOU MAY ...   \n",
       "\n",
       "                                              tokens topic_true_name  \n",
       "0  [read, perform, product, data, t, carbon, fibe...           space  \n",
       "1  [titl, xterm, escap, sequenc, speak, non, stan...               x  \n",
       "2  [isra, press, mad, get, excit, impli, suggest,...         mideast  \n",
       "4     [isra, soldier, kill, yr, old, child, probabl]         mideast  \n",
       "5  [news, miss, apr, news, miss, apr,           ,...         mideast  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_data[['content', 'tokens', 'topic_true_name']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T16:48:58.174722Z",
     "start_time": "2019-08-22T16:48:58.163603Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of token: 29\n",
      "Mean number of token: 9.46\n",
      "Voc size: 2126\n",
      "Number of documents: 1705\n"
     ]
    }
   ],
   "source": [
    "print(\"Max number of token:\", np.max(tokenized_data.nb_token))\n",
    "print(\"Mean number of token:\", round(np.mean(tokenized_data.nb_token),2))\n",
    "\n",
    "# Input format for the model : list of strings (list of tokens)\n",
    "docs = tokenized_data['tokens'].tolist()\n",
    "vocab = set(x for doc in docs for x in doc)\n",
    "n_terms = len(vocab)\n",
    "\n",
    "print(\"Voc size:\", n_terms)\n",
    "print(\"Number of documents:\", len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T09:12:53.917711Z",
     "start_time": "2019-08-21T09:07:51.566603Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train a new model \n",
    "\n",
    "# Init of the Gibbs Sampling Dirichlet Mixture Model algorithm\n",
    "mgp = MovieGroupProcess(K=10, alpha=0.1, beta=0.1, n_iters=30)\n",
    "\n",
    "vocab = set(x for doc in docs for x in doc)\n",
    "n_terms = len(vocab)\n",
    "n_docs = len(docs)\n",
    "\n",
    "# Fit the model on the data given the chosen seeds\n",
    "y = mgp.fit(docs, n_terms)\n",
    "\n",
    "# Save model\n",
    "with open('dumps/trained_models/model_v2.model', \"wb\") as f:\n",
    "    pickle.dump(mgp, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T16:49:00.020937Z",
     "start_time": "2019-08-22T16:49:00.014120Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the model used in the post\n",
    "filehandler = open('dumps/trained_models/model_v1.model', 'rb')\n",
    "mgp = pickle.load(filehandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T16:49:01.839951Z",
     "start_time": "2019-08-22T16:49:01.824734Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents per topics : [130 193 151 145 306 140 139 251 119 131]\n",
      "********************\n",
      "Most important clusters (by number of docs inside): [4 7 1 2 3 5 6 9 0 8]\n",
      "********************\n",
      "Cluster 4 : [('problem', 64), ('window', 60), ('xr', 55), ('server', 49), ('run', 47)]\n",
      "-----------------------------\n",
      "Cluster 7 : [('isra', 116), ('israel', 56), ('hezbollah', 40), ('expans', 34), ('terror', 31)]\n",
      "-----------------------------\n",
      "Cluster 1 : [('motif', 47), ('widget', 44), ('need', 34), ('program', 30), ('window', 22)]\n",
      "-----------------------------\n",
      "Cluster 2 : [('moon', 40), ('billion', 34), ('year', 29), ('race', 21), ('long', 19)]\n",
      "-----------------------------\n",
      "Cluster 3 : [('space', 70), ('station', 28), ('vandal', 28), ('sky', 28), ('design', 21)]\n",
      "-----------------------------\n",
      "Cluster 5 : [('armenian', 89), ('turkish', 45), ('armenia', 34), ('muslim', 27), ('genocid', 26)]\n",
      "-----------------------------\n",
      "Cluster 6 : [('space', 58), ('news', 26), ('mine', 22), ('time', 19), ('commerci', 18)]\n",
      "-----------------------------\n",
      "Cluster 9 : [('orbit', 39), ('dc', 24), ('comet', 21), ('temporari', 19), ('jupit', 19)]\n",
      "-----------------------------\n",
      "Cluster 0 : [('israel', 26), ('center', 20), ('orion', 17), ('zionism', 16), ('polici', 16)]\n",
      "-----------------------------\n",
      "Cluster 8 : [('space', 52), ('faq', 43), ('archiv', 26), ('question', 24), ('modifi', 22)]\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "doc_count = np.array(mgp.cluster_doc_count)\n",
    "print('Number of documents per topics :', doc_count)\n",
    "print('*'*20)\n",
    "\n",
    "# Topics sorted by document inside\n",
    "top_index = doc_count.argsort()[-10:][::-1]\n",
    "print('Most important clusters (by number of docs inside):', top_index)\n",
    "print('*'*20)\n",
    "\n",
    "\n",
    "# Show the top 5 words by cluster, it helps to make the topic_dict below\n",
    "top_words(mgp.cluster_word_distribution, top_index, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T16:49:05.084867Z",
     "start_time": "2019-08-22T16:49:03.760567Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-22 18:49:03,763 :: [INFO] :: ---- Topic allocation started ----\n",
      "2019-08-22 18:49:03,765 :: [INFO] :: Topic ID attribution...\n",
      "2019-08-22 18:49:04,330 :: [INFO] :: Topic ID probability computing...\n",
      "2019-08-22 18:49:04,880 :: [INFO] :: Applying confidence threshold and topic names matching...\n",
      "2019-08-22 18:49:05,082 :: [INFO] :: ---- Topic allocation completed ----\n"
     ]
    }
   ],
   "source": [
    "# Must be hand made so the topic names match the above clusters regarding their content\n",
    "topic_dict = {}\n",
    "topic_names = ['x',\n",
    "               'mideast',\n",
    "               'x',\n",
    "               'space',\n",
    "               'space',\n",
    "               'mideast',\n",
    "               'space',\n",
    "               'space',\n",
    "               'mideast',\n",
    "               'space']\n",
    "\n",
    "for i, topic_num in enumerate(top_index):\n",
    "    topic_dict[topic_num]=topic_names[i]\n",
    "    \n",
    "df_pred = topic_attribution(tokenized_data, mgp, topic_dict, threshold=0.4) # threshold can be modified to improve the confidence of the topics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T16:49:07.331708Z",
     "start_time": "2019-08-22T16:49:07.316798Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>topic_name</th>\n",
       "      <th>topic_true_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elevator to the top floor Reading from a Amoco...</td>\n",
       "      <td>x</td>\n",
       "      <td>space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Title for XTerm Yet again,the escape sequences...</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From Israeli press. Madness. Before getting ex...</td>\n",
       "      <td>mideast</td>\n",
       "      <td>mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How many israeli soldiers does it take to kill...</td>\n",
       "      <td>mideast</td>\n",
       "      <td>mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NEWS YOU MAY HAVE MISSED, Apr 20 NEWS YOU MAY ...</td>\n",
       "      <td>space</td>\n",
       "      <td>mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Alaska Pipeline and Space Station! on Date: 01...</td>\n",
       "      <td>space</td>\n",
       "      <td>space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HELP  xdm &amp; Solaris2.1 I recently read here th...</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Space FAQ 08/15 - Addresses Archive-name: spac...</td>\n",
       "      <td>space</td>\n",
       "      <td>space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WANTED  X &amp; security posting A few days ago th...</td>\n",
       "      <td>mideast</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>From Israeli press. TORTURE. From: Center for ...</td>\n",
       "      <td>mideast</td>\n",
       "      <td>mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>finding out state of state keys (eg, CapsLock ...</td>\n",
       "      <td>space</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Xsun not running on SPARCclassic I've installe...</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Commercial mining activities on the moon What ...</td>\n",
       "      <td>space</td>\n",
       "      <td>space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Asynchronous X Windows? No, it isn't</td>\n",
       "      <td>mideast</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Why not give $1 billion to first year-lo For t...</td>\n",
       "      <td>space</td>\n",
       "      <td>space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Automated X testing : Does anyone know what is...</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>rejoinder. Questions to Israelis A number of p...</td>\n",
       "      <td>mideast</td>\n",
       "      <td>mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Galileo Update - 04/15/93 Forwarded from Neal ...</td>\n",
       "      <td>space</td>\n",
       "      <td>space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>How to mask the left button? [I am posting thi...</td>\n",
       "      <td>space</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>how to put RPC in HP X/motif environment? Hi, ...</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              content topic_name  \\\n",
       "0   Elevator to the top floor Reading from a Amoco...          x   \n",
       "1   Title for XTerm Yet again,the escape sequences...          x   \n",
       "2   From Israeli press. Madness. Before getting ex...    mideast   \n",
       "4   How many israeli soldiers does it take to kill...    mideast   \n",
       "5   NEWS YOU MAY HAVE MISSED, Apr 20 NEWS YOU MAY ...      space   \n",
       "6   Alaska Pipeline and Space Station! on Date: 01...      space   \n",
       "7   HELP  xdm & Solaris2.1 I recently read here th...          x   \n",
       "8   Space FAQ 08/15 - Addresses Archive-name: spac...      space   \n",
       "9   WANTED  X & security posting A few days ago th...    mideast   \n",
       "10  From Israeli press. TORTURE. From: Center for ...    mideast   \n",
       "11  finding out state of state keys (eg, CapsLock ...      space   \n",
       "12  Xsun not running on SPARCclassic I've installe...          x   \n",
       "13  Commercial mining activities on the moon What ...      space   \n",
       "14               Asynchronous X Windows? No, it isn't    mideast   \n",
       "15  Why not give $1 billion to first year-lo For t...      space   \n",
       "18  Automated X testing : Does anyone know what is...          x   \n",
       "20  rejoinder. Questions to Israelis A number of p...    mideast   \n",
       "21  Galileo Update - 04/15/93 Forwarded from Neal ...      space   \n",
       "22  How to mask the left button? [I am posting thi...      space   \n",
       "23  how to put RPC in HP X/motif environment? Hi, ...          x   \n",
       "\n",
       "   topic_true_name  \n",
       "0            space  \n",
       "1                x  \n",
       "2          mideast  \n",
       "4          mideast  \n",
       "5          mideast  \n",
       "6            space  \n",
       "7                x  \n",
       "8            space  \n",
       "9                x  \n",
       "10         mideast  \n",
       "11               x  \n",
       "12               x  \n",
       "13           space  \n",
       "14               x  \n",
       "15           space  \n",
       "18               x  \n",
       "20         mideast  \n",
       "21           space  \n",
       "22               x  \n",
       "23               x  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd.set_option('display.max_columns', None)  \n",
    "#pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "df_pred[['content', 'topic_name', 'topic_true_name']].head(20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T16:49:09.314695Z",
     "start_time": "2019-08-22T16:49:09.309072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic Accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "print(\"Topic Accuracy:\", round(np.sum(np.where((df_pred['topic_true_name'] == df_pred['topic_name']), 1, 0))/len(df_pred), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive cluster visualization with pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-22T16:48:50.933Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the cluster in a notebook\n",
    "plot_topic_notebook(tokenized_data, docs, mgp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
